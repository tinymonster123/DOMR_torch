IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024

1455

DOMR: Toward Deep Open-World
Malware Recognition
Tingting Lu

and Junfeng Wang

Abstract— Deep learning has been widely used for Android
malware family recognition, but current deep learning-based
approaches make the closed-world assumption that malware families encountered during testing are available at training phase.
Unfortunately, this assumption is often violated in practice due
to the constant emergence of novel categories and the huge cost
of collecting abundant training classes, causing serious failures
to the existing approaches. Accordingly, a new problem setting
for Android malware family recognition is introduced, i.e., deep
open-world malware recognition that poses two critical tasks:
1) Open recognition, aiming to not only classify malware from
known families (present in training) but detect malware from
unknown families (absent in training); 2) Incremental update,
aiming to learn about the detected unknown/new categories
without retraining from scratch and catastrophically forgetting
the previously learned known/old classes. This paper formalizes
the problem and proposes a novel solution called DOMR to
address the above two tasks in a unified framework. The core of
DOMR is an episode-based representation learning scheme that
mimics the open-world setting through episodic training to learn
a generalizable representation. The key insight is that the training
process following the open-world setting forces the representation
to accumulate experience in open recognition, thereby facilitating
both the classification of known family instances and the detection
of unknown family instances at inference. Given this representation, multiple one-vs-rest classifiers are subsequently built to
make the final recognition decision through an aggregative strategy. Comparative experiments show that DOMR outperforms
start-of-the-art methods, with macro-averaged F1-scores obtained
on two datasets reaching 80.88% and 56.17% in the open case,
and 79.34% and 49.55% in the incremental case, respectively.
Ablation studies further analyze the effectiveness of DOMR in
achieving the open recognition and incremental update goals.
Index Terms— Android malware, malware family recognition,
open-world malware recognition, deep learning, meta-learning.

I. I NTRODUCTION

G

IVEN the huge threat of Android malware to today’s
mobile ecosystem [1], [2], [3] and the great success of
deep learning in building security applications [3], [4], [5],
Manuscript received 27 April 2023; revised 20 September 2023;
accepted 20 November 2023. Date of publication 30 November 2023; date
of current version 11 December 2023. This work was supported in part
by the National Key Research and Development Program under Grant
2022YFB3305203, in part by the National Natural Science Foundation of
China under Grant U2133208 and Grant 62101368, in part by the Sichuan
Youth Science and Technology Innovation Team under Grant 2022JDTD0014,
and in part by the Major Science and Technology Special Project of
Sichuan Province under Grant 2022ZDZX0008. The associate editor coordinating the review of this manuscript and approving it for publication was
Dr. Chunyi Peng. (Corresponding author: Junfeng Wang.)
The authors are with the College of Computer Science, Sichuan University,
Chengdu 610065, China (e-mail: lutt_scu@qq.com; wangjf@scu.edu.cn).
Digital Object Identifier 10.1109/TIFS.2023.3338469

deep learning-based Android malware family recognition
has drawn considerable interest from the mobile security
community and been a recent research focus. While deep
learning-based methods [6], [7], [8], [9], [10], [11] have
achieved state-of-the-art performance, they work under the
closed-world assumption that all malware families to expect
at inference would be appearing in training. As a result, such
learning-driven recognition models are unaware what they do
not know, confidently classifying any malware encountered in
the future into one of the known families.
Unfortunately, the real-life environments where the recognition models will be deployed are usually open and
ever-changing over time [12], [13], facing myriad unknown
malware families inevitably. On the one hand, obtaining all
existing families to train the models before deployment is
almost impossible, since malware is always privately owned
until used to carry out an attack. On the other hand, novel
families are constantly emerging [12] due to the adversarial
evolution nature of this field. Consequently, the closed-world
assumption is often violated in practice, causing serious
failures (i.e., instances from unknown families are all misclassified into known ones) to the deployed models and, even
worse, severe damage to the deployment environments once
the misclassification results are employed for threat assessment
and defense planning. Hence the need arises for studying
deep learning-based solutions that break the closed-world
assumption and have the essential capabilities of rejecting
unknown malware families and adapting to these categories,
which is referred to in this paper as the deep open-world
malware recognition problem.
Deep open-world malware recognition poses two crucial
tasks: Open recognition and Incremental update. The former
works to endow a recognition model with the capability of
recognizing what it does not know, that is, to enable the
model to detect malware from unknown families as unknown
while classifying malware from known families into their
respective categories. The latter strives to incorporate the
detected unknown families into the model at minimal cost as
long as the corresponding labels become available. However,
jointly addressing these two tasks is non-trivial and confronted
with several challenges:
•

Biased learning. Recognizing instances from unknown
categories as unknown requires strong generalization [14].
But with traditional learning paradigms (e.g., mini-batch
SGD and cross-entropy loss), the recognition model is
optimized only for known families without considering

1556-6021 © 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

1456

IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024

the open-world setting during training. Consequently, the
model heavily overfits the known classes and fails to speculate the latent space for unknown categories. In other
words, the biased learning process makes the model
hardly generalizable to detect malware from unknown
families, degrading the open recognition performance.
• Catastrophic forgetting. Retraining from scratch is the
most straightforward way to learn about well-labeled
unknown families, but doing so is naïve because retraining with all previous data is extremely time-consuming
and storage-costly [15]. Incrementally updating the recognition model with these new categories is thus a more
desirable and natural choice. Nevertheless, it suffers from
catastrophic forgetting [16], i.e., the knowledge learned
from old classes tends to be overwritten when fine-tuning
the model with only new category instances, resulting in
severe performance deterioration on old family classification after the incremental update.
• Representation drift. Worse still, shifts in the family
label space of the test data from that of the training
data are usually accompanied by changes in the feature
representation space [17], [18], termed representation
drift. If a fixed representation space (i.e., the one trained
with old classes) is utilized throughout the incremental
update, representation drift is likely to induce embedding
confusion between new categories and others (i.e., old and
unknown classes). In such case, the recognition model
will perform poorly on new family classification.
To the best of our knowledge, there have been no attempts
toward tackling all these challenges of both tasks for developing a solution to deep open-world malware recognition.
In this paper, we propose DOMR, a novel approach that
deals with the aforementioned challenges and achieves the
open recognition and incremental update goals in a unified
framework. The core of DOMR is to learn a generalizable
and adaptive representation followed by multiple one-vs-rest
classifiers. More specifically, DOMR mimics the open-world
setting through meta-learning to explicitly optimize the representation for both known and unknown families during
training, where center-distance loss is designed to enhance
the optimization, thereby overcoming the biased learning issue
and enabling the representation to generalize well to unknown
families. Exemplar replay techniques are integrated into the
representation learning scheme to consolidate the knowledge
of old families while adapting to new ones at each incremental
update stage, thus mitigating the catastrophic forgetting and
representation drift issues. Based on the learned representation,
multiple one-vs-rest classifiers are built, each determining
whether a test malware belongs to the corresponding category,
and DOMR fuses them to make the final decision on malware
family recognition via an aggregation strategy.
We evaluate DOMR with extensive experiments on two
network feature sets (denoted as Drebin_NT and CICMalDroid2020_NT) collected for the real-life Android malware
datasets Drebin [19] and CICMalDroid2020 [20]. The results
show that DOMR outperforms six related methods, with
macro-averaged F1-scores ranging from 61.41% to 80.88% on
Drebin_NT and from 47.73% to 56.17% on CICMalDroid_NT

at different open settings, and ranging from 57.08% to
79.34% on Drebin_NT and from 44.54% to 49.55% on
CICMalDroid_NT at different incremental settings. Ablation
studies also demonstrate the benefits of meta-learning and
center-distance loss for open recognition, as well as the
detrimental effects of fixed representation and fine-tuning
for incremental update. Our evaluation indicates that DOMR
would be a promising solution to open-world Android malware
recognition.
In summary, this paper makes the following contributions:
• A new problem setting for Android malware family
recognition is introduced, namely deep open-world malware recognition, which models real-life environments
more closely. Moreover, the main challenges faced in
addressing the two tasks of this problem are analyzed.
• A novel deep open-world malware recognition approach,
DOMR, is proposed, which considers both open recognition and incremental update tasks and solves their
challenges in a unified framework.
The rest of this paper is organized as follows. Section II
defines the problem scope of the research. Section III introduces DOMR in detail. Evaluation and experimental results
are shown in Section IV. Section V discusses related work.
Section VI provides several discussions on limitations and
future work. Finally, we conclude the paper in Section VII.
II. P ROBLEM S COPE
A. Threat Model & Goals
1) Threat Model: A deep learning-based malware family
recognition model trained in-house faces adversarial threats
when ported to a deployment environment. The threats come
mainly from two aspects: unknown malware (unknown variants of known families and instances of unknown families)
and attacks [21] against deep learning itself. We focus on the
former and assume that the adversary tries to evade recognition
through the first threat. As for the latter, although also a very
important and active research topic, it is beyond the scope of
this paper.
To train a deep learning-based recognition model,
we assume that the sample size of a malware family is
sufficient, at least enough to support neural networks to
learn highly discriminative features without severe overfitting.
In other words, the scope of this paper does not cover the
few-shot setting where a category typically has fewer than
10 samples. Moreover, we trust our datasets are reliable,
i.e., the family labels of the samples in these datasets are
ground-truth.
2) Goals: First, this work strives to understand the gap
between theoretical research on deep learning-based Android
malware family recognition and real-life deployment environments, and further introduces the deep open-world malware
recognition problem to bridge the gap.
Second, we aim to provide a unified framework to solve
both open recognition and incremental update tasks of this
problem, with a focus on designing a learning scheme that
can generate effective recognition models for open recognition.
Note that we do not invent new solutions for incremental

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

LU AND WANG: DOMR: TOWARD DEEP OPEN-WORLD MALWARE RECOGNITION

Fig. 1.

1457

High-level architecture of DOMR.

update, but rather attempt to integrate exemplar replay-based
class-incremental learning techniques into the learning scheme
to support this task.
B. Problem Formulation
Suppose f φ,θ is a deep open-world malware recognition
model (ORM) parameterized by φ for the representation
network and θ for the classifier part. At any time t, we have
t−1
a pre-trained ORM f φ,θ
that is aware of a set of known
families Kt−1 = {c1 , · · · , ca } but unaware of a set of unknown
families U = {ca+1 , · · · }, and receive some test malware
that may be from Kt−1 or U. Note that no data from U are
t−1
available when learning f φ,θ
. The deep open-world malware
recognition problem can then be formulated as follows:
t−1
• Open recognition: f φ,θ is utilized to classify the test
t−1
malware from K
into ci (1 ≤ i ≤ a) and detect the
malware from U as c0 (unknown). Assume that b new
families1 are identified from c0 and denoted as K̂t =
{ca+1 , · · · , ca+b }.
t−1
t
• Incremental update: f φ,θ
is updated to f φ,θ
by
t
incrementally learning about K̂ while mitigating the
catastrophic forgetting of Kt−1 . The sets of known and
unknown families now become Kt = Kt−1 ∪ K̂t and
U = {ca+b+1 , · · · }, respectively.
This process iterates throughout the life of the recognition.
III. M ETHODOLOGY
Fig. 1 shows the high-level architecture of DOMR that has
two key components:
• Learner. At time t ≥ 1, with the training samples of the
t−1
known families Kt and the pre-trained ORM f φ,θ
, this
module learns a generalizable and adaptive representation
f φt and multiple one-vs-rest classifiers f θt for subsequent
1 In this paper, it is assumed that new families are labeled by security
analysts from the unknown category c0 , which will be discussed in Section VI.

recognition, which unifies initial training and incremental
update in one learning scheme (Section III-A).
• Recognizer. At time t ≥ 2, this part receives a set of
test samples possibly from the known families Kt−1 or
the unknown families U, embeds them via f φt−1 , and
finally predicts the family of these samples through f θt−1
coupled with an aggregation strategy (Section III-B).
After recognition, the samples detected as the unknown category c0 are forwarded to security analysts for labeling. The
learner component is then scheduled to incrementally learn
about the newly labeled families K̂t to update the ORM.
A. Learner
Hassen et al. [22] made the first attempt to mitigate the
biased learning issue by learning a neural network-based representation using a novel loss function that optimizes inter-class
and intra-class distances to free up more space among known
families for latent unknown families to occupy. Despite the
pioneering, this method does not explicitly learn to detect
unknown family instances, and thus the learned representation
still does not generalize well to unknown families.
Inspired by the powerful generalization of meta-learning,
we design an episode-based representation learning scheme,
which mimics the open-world setting through episodic training to learn a generalizable representation that is explicitly
optimized for both known and unknown families. Exemplar
replay techniques are further integrated into the scheme to
consolidate the knowledge of old families while adapting to
new ones at each incremental update stage.
After representation learning, suitable recognition decisions
should be designed to detect unknown family instances while
classifying known family instances. Most methods [22], [23],
[24], [25], [26] rely on rejection thresholds to achieve this.
However, thresholds are usually determined empirically based
on a large number of known family instances, which inevitably
brings risks due to the lack of information about unknown
families [27] and is also non-trivial to do in incremental

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

1458

IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024

Fig. 2.

Schematic diagram of the overall learning scheme.

stages when only limited exemplars of known families are
available. Given these, we adopt a one-vs-rest strategy to build
multiple binary classifiers to make the recognition decision
of DOMR threshold-free. The overall learning scheme is
illustrated in Fig. 2.
1) Episode-Based Representation Learning: In standard
meta-learning, an episode T consists of a support set S and
a query set Q, which are disjoint but sampled from the
same label space. To consider the open-world setting during
training, our approach splits Q into a known query set Q k
and an unknown query set Q u , and defines an episode as
T = (S, Q k , Q u ) where the label spaces of S and Q k
are identical but disjoint from Q u . Therefore, the training
proceeds in such a way that S and Q k serve as samples
of known families while Q u acts as instances of unknown
families (actually pseudo-unknown families, rather than the
real unknown families encountered during testing). In this
way, a base network f φ ′ learned from S can be utilized to
train the representation network f φ by optimizing for the
recognition performance of f φ ′ on Q k and Q u . In other words,
this training process forces f φ to accumulate experience in
open recognition, thereby facilitating both the classification
of known families and the detection of unknown families at
inference.
To further support incremental update, at time t ≥ 1, T is
randomly sampled from an augmented training set containing
newly labeled instances of K̂t and stored exemplars2 of Kt−1 ,
such that the update of f φt−1 can be regularized through these
2 For each family, exemplars are some representative samples but as few as
possible.

exemplars to mitigate the catastrophic forgetting of Kt−1 when
learning about K̂t . This also makes it easy to unify initial
and incremental training, simply by setting K0 to the empty
set. To comply with the disjointness between S/Q k and Q u ,
the label space of S/Q k is set as the union of Kt−1 and a
subset3 of K̂t , while the rest of K̂t is used as the label space
of Q u . As such, optimizing f φ ′ over S by starting with f φt−1
undertakes the actual incremental task.
We implement this idea based on the classic meta-learning
framework MAML [28], which involves an inner-outer optimization over a batch of episodes as shown in Fig. 2. The
inner learns new knowledge from each episode in incremental
form while the outer aggregates the knowledge learned from
all episodes to produce a generalizable representation.
Inner Optimization: For episode Ti in the batch, its base
network parameters φi′ are first initialized using φ t−1 and then
optimized over Si by minimizing the following cost function:
Ls (Si , φi′ ) = E(xm ,ym )∼Si ,ym ∼K̂t [λ1 ℓ1 (xm , ym ) + ℓ2 (xm , ym )]
i

+ E(xm ,ym )∼Si ,ym ∼Kt−1 λ2 ℓ3 (xm , ym ).

(1)

Here, ℓ1 and ℓ2 applied to the new family instances in Si
are center-distance loss and cross-entropy loss, respectively;
ℓ3 applied to the old family instances in Si is distillation loss;
λ1 and λ2 are balancing parameters. ℓ1 is designed to enhance
intra-family compactness and inter-family separability to free
up more space among these known families for latent unknown
3 In the current implementation, this subset has only one family, randomly
sampled from K̂t .

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

LU AND WANG: DOMR: TOWARD DEEP OPEN-WORLD MALWARE RECOGNITION

families to occupy, facilitating open recognition, defined as
ℓ1 (xm , ym ) = log

dφi′ (xm , u ym )
min
ŷ∈K̂it ∪Kt−1 | ŷ̸= ym

dφi′ (xm , u ŷ )

,

(2)

where dφi′ (•) is the Euclidean distance between sample xm
and centroid u c in the representation space φi′ , and u c is
calculated as the mean value of the instances in family c.
ℓ2 aims to reduce classification errors to learn discriminative
features from the new families, formulated as
X
ℓ2 (xm , ym ) = −
λ log pφi′ (y = ŷ|xm )
ŷ∈K̂it ∪Kt−1

= − log pφi′ (y = y m |xm ),

(3)

where pφi′ (•) is the predicted probability of classifying sample
xm into family ŷ using a softmax classifier in the representation space φi′ (note that the classifier is only used for
representation learning, not for the actual recognition task);
λ equals 1 if ŷ = ym and 0 otherwise. ℓ3 encourages the
base network to reproduce the results predicted using the
pre-update parameters for the stored exemplars to preserve
the discriminative features previously learned from the old
families, expressed as
X
ℓ3 (xm , ym ) = −
pφ t−1 (y = ŷ|xm ) log pφi′ (y = ŷ|xm ).

1459

To optimize the parameters θit (1 ≤ i ≤ a + b), the learning
scheme takes all exemplars belonging to family ci ∈ Kt
as positive samples and the rest as negative ones, and then
minimizes the following cost function:
Lc (M, φ t , θit ) = −E(xm ,ym )∼M [λ log pφ t ,θ t (y = ci |xm )
i

+ (1 − λ)(1 − log pφ t ,θ t (y = ci |xm ))], (6)
i

(•) is the predicted
probability of classifying sample xm into ci using θit in the
representation space φ t ; λ equals 1 if ym = ci and 0 otherwise. This optimization process encourages each classifier
to learn more specialized discriminative features to generate
family-specific decision boundaries, thereby providing determinant information for the final recognition.

where M is the exemplar set of Kt ; p

φ t ,θit

B. Recognizer
In the inference phase, DOMR adopts an aggregation strategy to make decisions on open recognition, which is depicted
in Algorithm 1. At time t ≥ 2, given a test malware x, DOMR
first embeds it using f φt−1 and then determines its family
by fusing the predictions of all classifiers in f θt−1 . If every
classifier detects the malware as a negative sample, it is labeled
as c0 ; otherwise, it is classified into the family corresponding
to the classifier with the highest predicted probability.

ŷ∈Kt−1

(4)
Outer Optimization: At this point, the representation network parameters φ t−1 are updated over all episodes of the
batch by minimizing the following cost function:
X
[Lk (Q ik , φi′ ) + Lu (Q iu , φi′ )],
Ti

Lk (Q ik , φi′ ) = E(xm ,ym )∼Q k ℓ2 (xm , ym ),
i
X
Lu (Q iu , φi′ ) = E(xm ,ym )∼Q iu

pi ∈[0,1]

4:

ŷ∈K̂it ∪Kt−1

pφi′ (y = ŷ|xm ) log pφi′ (y = ŷ|xm ).

Algorithm 1 Open Recognition With an Aggregation Strategy
Input: x // the test malware to be recognized
f φt−1 // the representation network trained at time t − 1
f θt−1 // the classifiers trained at time t − 1
Output: y // the predicted family of x and y ∈ Kt−1 ∪ {c0 }
t−1
1: x ′ ← f φ (x)
t−1
2: for f θi in f θ
do
3:
pi ← max f θi (x ′ ) // the predicted probability
obtained by f θi
yi ← arg max f θi (x ′ ) // the predicted category
yi ∈{0,1}

(5)

Here, Lk (•) applied to Q ik ensures the update moves toward
the optimal classification performance of these known families; Lu (•) applied to Q iu encourages the update in the
direction of classifying these samples into any known family
with a low probability such that the parameters are improved
for rejecting the pseudo-unknown families, making the final
representation generalize well to the real unknown families
encountered during testing.
By iteratively performing the above two optimizations,
the scheme eventually derives the representation f φt that has
learned the new families K̂t without catastrophically forgetting
the old ones Kt−1 and has accumulated a wealth of knowledge
useful for inferring unknown families.
2) Classifier Generation: Given the learned representation
f φt , our approach first updates the exemplar set of the known
families Kt using the method
described
n
o in [15] and then trains
t
t
t
the classifiers f θ = f θ1 , · · · , f θa+b on this exemplar set,
each essentially a binary classifier with softmax activation.

obtained by f θi , with 0 denoting negative class and 1
denoting positive class
5: end for
//aggregation

if ∀yi = 0

 c0
y←
(7)

 arg max pi otherwise
ci ∈Kt−1

Subsequently, the samples detected as the unknown category
c0 are forwarded to security analysts for labeling. The newly
labeled instances of K̂t and the exemplar set of Kt−1 are
merged to generate an augmented training set, which is then
t−1
t .
utilized to incrementally update the ORM f φ,θ
to f φ,θ
IV. E VALUATION
We evaluate DOMR from the following three aspects:
• Effectiveness (Section IV-B). This part investigates
the recognition performance of DOMR in both open

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

1460

IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024

and incremental cases through the following research
questions:
RQ1: What is the overall performance of DOMR
in classifying known family instances (known family
classification) and detecting unknown family instances
(unknown detection) compared to relevant methods?
RQ2: How does DOMR perform after incrementally
learning new families compared to relevant methods?
• Ablation (Section IV-C). This part studies the impact of
critical components in DOMR on the open and incremental recognition performance through the following
research questions:
RQ3: Do meta-learning and center-distance loss benefit
the open recognition task, and how do they specifically affect known family classification and unknown
detection?
RQ4: Are fixed representation and fine-tuning detrimental
to the incremental update task (i.e., is adaptive representation learning necessary for this task), and what
are the specific effects of both on old and new family
classification?
• Sensitivity (Section IV-D). This part further analyzes
other factors that may affect the effectiveness and efficiency of DOMR, including hyperparameters, sample
size, temporal evolution, and incremental overhead.
A. Experimental Setup
1) Datasets: Our original malicious Android applications
come from two real-world datasets, i.e., Drebin [19] and
CICMalDroid2020 [20]; the former is a widely used benchmark with ground-truth labels, while the latter is a recently
released one with a larger sample size. While DOMR is
a feature-agnostic Android malware recognition framework,
we provide an implementation based on the network behavior
features proposed in [10]. Therefore, we utilize the network
traffic collected for both Android malware datasets as our
final datasets, denoted as Drebin_NT and CICMalDroid_NT,
respectively. For more details on the collection of these
network traffic datasets, see [10], and TABLE I shows their
statistics.
2) Evaluation Protocols: For open-world evaluation, training utilizes only samples from known classes, while testing
uses those from both known and unknown classes [29]. Thus,
we select N malware families randomly per dataset as known
categories and the rest as an unknown category (i.e., c0 ). The
training-test sets are split by stratified sampling in a 5:1 ratio
for the known. The unknown category instances are all added
to the test sets. The recognition model is built on the training
set and eventually evaluated on the test set.
To evaluate the recognition performance of DOMR in
the open case, we consider four different settings, i.e.,
N ∈ {4, 5, 6, 7} for Drebin_NT and N ∈ {7, 9, 11, 13} for
CICMalDroid_NT. For the incremental case, we consider three
different settings; for Drebin_NT, 1, 2, and 3 new families are
added individually to the model trained on 4 old families; for
CICMalDroid_NT, 2, 4, and 6 new families are incorporated
into the model trained on 7 old families separately. Under
these incremental settings, the updated models are ultimately

TABLE I
S TATISTICS OF THE DATASETS U SED IN T HIS W ORK

built with N ∈ {5, 6, 7} for Drebin_NT and N ∈ {9, 11, 13}
for CICMalDroid_NT.
3) Metrics: Macro-averaged F1-score (MAF) is a commonly used metric to evaluate the recognition performance of
an open-world method across multiple categories. However,
MAF treats all categories equally and thus regards the importance of unknown classes as equivalent to that of a known
class, which is problematic in the malware domain since
misclassifying unknown family instances as known families
leads to more severe security issues. Hence, we adopt both
MAF and weighted-averaged F1-score (WAF) as metrics to
measure the recognition performance of DOMR. Due to the
inherent imbalance of our datasets and the aforementioned
protocols, the unknown category c0 in each test set would
be the majority category especially when N is small, so the
WAF values are more influenced by the unknown detection
performance.
4) Implementation Details: We develop DOMR in Python
with PyTorch and Scikit-learn. The representation network
is built on the classic convolutional neural network (CNN)
LeNet5 [30]. Each one-vs-rest classifier is implemented as a
three-layer perceptron with 128, 16, and 2 neurons, respectively, and the number of neurons in the two hidden layers
is determined by performing cross-validation on the training
sets. The loss weights λ1 and λ2 are set to 1. The Adam
optimizer [31] with a learning rate of 0.001 is used to
train the networks over 100 epochs. For a fairer comparison,
the baseline methods in this paper adopt the same network
architecture and optimization procedure as DOMR
5) Baselines: To our knowledge, there is no work targeting
deep open-world malware recognition in the true sense, and the
only one [22], denoted as IILoss, attempts to tackle the open
recognition task while ignoring the incremental update task.
Therefore, we consider IILoss and three methods, OpenMax
[23], G-OpenMax [25], and OVRN-CD [24], from the field of
open-set image classification, as well as DOC [26], from the
field of open-set text classification, as our open recognition
baselines. Furthermore, the state-of-the-art method EVM [32]

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

LU AND WANG: DOMR: TOWARD DEEP OPEN-WORLD MALWARE RECOGNITION

1461

Fig. 3. Performance comparison of DOMR with five baseline methods on Drebin_NT at four different N values, where N is the number of known families.

Fig. 4. Performance comparison of DOMR with five baseline methods on CICMalDroid_NT at four different N values, where N is the number of known
families.

for open-world image classification is employed as an incremental recognition baseline.
IILoss learns a neural network-based representation space
via the ii-loss function, in which a threshold-based outlier
detector and a softmax classifier are utilized to detect unknown
category instances and classify known category instances,
respectively. OpenMax extends the softmax layer of a neural network to provide the probability of an instance from
unknown categories by revising the softmax probabilities
with the Weibull probabilistic models of known categories.
G-OpenMax augments OpenMax with explicit probability
estimation over unknown categories, which is done based on
unknown category instances synthesized through generative
adversarial networks. DOC replaces the softmax layer of a
neural network with a one-vs-rest layer containing multiple
sigmoid functions for known categories, rejects an instance
if all sigmoid probabilities are less than the corresponding thresholds estimated via Gaussian fitting, and otherwise
classifies it into the category with the highest probability.
OVRN-CD is an extended version of DOC, where the one-vsrest sigmoid layer is replaced by multiple one-vs-rest sigmoid
networks and the recognition decision is made based on logits
rather than sigmoid probabilities. EVM is a theoretically sound
and scalable classifier derived from extreme value theory,
which constructs a compact representation of the decision
boundary for each known category to facilitate open recognition and incremental update.

B. Effectiveness
1) Open Recognition Performance: (RQ1). We reimplement
the five open recognition baselines and train their models under
four different open settings separately. We then measure the
recognition performance of each model on the corresponding
test set. The final comparison results are shown in Fig. 3
and Fig. 4.
It can be seen that OVRN-CD and OpenMax obtain very
low WAF values on both datasets, especially when N is small.
This is because a large number of unknown family instances
are misclassified into known families, which is essentially
caused by a biased training process. Specifically, they build the
recognition models by optimizing only the classification loss
among known families without considering any optimization
for potential unknown families, resulting in overgeneralized
boundaries for known families and thus prone to fail in
detecting unknown family instances.
Based on the pseudo-unknown family instances synthesized via adversarial generative networks, G-OpenMax makes
some optimizations for unknown detection when building the
recognition models and thus obtains higher WAF values than
OpenMax and OVRN-CD, particularly on Drebin_NT. However, the synthetic samples are still not representative of a wide
range of potential unknown families, as their generation relies
heavily on known family distributions, so the improvement of
G-OpenMax over OpenMax and OVRN-CD is not significant
on the more complex dataset CICMalDroid_NT.

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

1462

IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024

Fig. 5. Performance comparison between DOMR and EVM on Drebin_NT at three different incremental settings: 1, 2, and 3 new families. The number of
old families equals 4.

Fig. 6. Performance comparison between DOMR and EVM on CICMalDroid_NT at three different incremental settings: 2, 4, and 6 new families. The
number of old families equals 7.

Through enhancing intra-family compactness and interfamily separability to reserve more space for latent unknown
families to occupy, DOMR and IILoss achieve much higher
WAF values compared to OpenMax, G-OpenMax, and OVRNCD, with DOMR being significantly better. The WAF values
vary from 73.14% to 83.08% on Drebin_NT and from 60.42%
to 77.35% on CICMalDroid_NT for DOMR, while they are
from 46.63% to 64.8% on Drebin_NT and from 22.15% to
52.76% on CICMalDroid_NT for IILoss. The better performance of DOMR results from the explicit optimization for
unknown families during training.
Although DOC achieves relatively high WAF values on both
datasets, second only to DOMR, its MAF values drop dramatically and are much lower than those of DOMR, meaning that
DOC performs well on unknown detection but fails in known
family classification. And these results also suggest that DOC
is closer to an outlier detector.
OVRN-CD shows improved results on the metric MAF
compared to WAF, but it still performs much worse than the
other methods except DOC, with a maximum MAF value
of 21.44% on Drebin_NT and 3.11% on CICMalDroid_NT.
These results indicate that OVRN-CD is weak in both known
family classification and unknown detection, yielding the
worst open recognition performance.
The MAF values of OpenMax far exceed its WAF values
on both datasets, implying that OpenMax is quite good at
known family classification despite being poor at unknown
detection. G-OpenMax and IILoss obtain comparable MAF
values to OpenMax, and these values are generally larger than

the corresponding WAF values. These are reasonable since
these three methods utilize a well-trained softmax classifier
to discriminate between known families, which is time-tested
to be effective for multiclass classification. These results also
suggest that OpenMax is closer to a closed-world approach
and therefore does not exhibit superior open recognition performance over G-OpenMax and IILoss.
While DOMR’s performance on the MAF metric decreases
compared to that on the WAF metric, it still outperforms
the other five methods overall, with MAF values ranging
from 61.41% to 80.88% on Drebin_NT and from 47.73%
to 56.17% on CICMalDroid_NT. From these results, it can
be concluded that DOMR achieves the best open recognition
performance.
2) Incremental Recognition Performance: (RQ2). We compare DOMR against EVM under three different incremental
settings. For each setting, a group of new families is introduced
to be incrementally learned by the model trained on old
families. We then measure the recognition performance of each
updated model on the corresponding test set, and the results
are shown in Fig. 5 and Fig. 6.
It can be seen that DOMR significantly outperforms EVM
in terms of WAF, with the former exceeding the latter by
27.43% to 41.8% on Drebin_NT and by 40.12% to 44.83%
on CICMalDroid_NT. The worse performance of EVM stems
mainly from the fixed representation adopted for incremental
update, which causes serious confusion between new and
unknown families and thus makes EVM perform poorly in
unknown detection.

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

LU AND WANG: DOMR: TOWARD DEEP OPEN-WORLD MALWARE RECOGNITION

1463

TABLE II
A BLATION C OMPARISON OF C RITICAL FACTORS IN O PEN R ECOGNITION . R ESULTS FOR D REBIN _NT
AND CICM AL D ROID _NT A RE O BTAINED AT N = 4 AND N = 7, R ESPECTIVELY

TABLE III
A BLATION C OMPARISON OF C RITICAL FACTORS IN I NCREMENTAL R ECOGNITION . R ESULTS FOR D REBIN _NT AND CICM AL D ROID _NT A RE
O BTAINED AT N = 7 (4 O LD FAMILIES P LUS 3 N EW FAMILIES ) AND N = 13 (7 O LD FAMILIES P LUS 6 N EW FAMILIES ), R ESPECTIVELY

The MAF values of EVM are much larger than the corresponding WAF values on both datasets, indicating that it
is more capable of classifying known family instances than
detecting unknown family instances. However, these values
decrease slightly as the number of new families increases.
This is because the fixed representation can also induce
confusion between new and old families as well as new
families themselves, weakening the performance on known
family classification.
By taking adaptive representation learning to mitigate the
confusion, DOMR yields higher MAF values than EVM
overall, ranging from 57.08% to 79.34% on Drebin_NT and
from 44.54% to 49.55% on CICMalDroid_NT. These results
suggest that DOMR achieves better incremental recognition
performance.
C. Ablation
1) Factors in Open Recognition: (RQ3). To examine
whether meta-learning and center-distance loss do bring benefits, we ablate both separately and compare the open recognition performance before and after the ablation. To understand
exactly how they affect the recognition results, we further
check the MAF values for unknown detection and known family classification respectively, where the former is measured
only on the unknown category c0 while the latter is calculated
on known families alone.
As can be seen from TABLE II, both meta-learning and
center-distance loss significantly affect the open recognition
performance regardless of the datasets, with WAF values
dropping sharply and MAF values decreasing as well after
the ablation.
In detail, without meta-learning, the unknown detection performance is greatly degraded, proving that the introduction of

meta-learning does enable the recognition model to generalize
well to detect unknown family instances. However, metalearning has no positive effect on known family classification
and the MAF values improve after the ablation, but this is
reasonable since the ablated models are optimized on the entire
training sets rather than on the query sets as in the metalearning paradigm, fitting the training sets better and resulting
in the improved performance.
Without center-distance loss, the performance of both
unknown detection and known family classification is considerably reduced, suggesting that the loss contributes positively
to these two tasks. Nevertheless, the MAF values for unknown
detection are still much higher than those in the absence
of meta-learning, indicating that meta-learning plays a more
crucial role in unknown detection.
2) Factors in Incremental Recognition: (RQ4). To verify the effectiveness of adaptive representation learning for
incremental update, we replace it with fixed representation
and fine-tuning separately and compare the open recognition
performance before and after the replacement. To further
investigate the specific impact on old and new families,
we examine the MAF values of both, which are the open
recognition results averaged over old families and new families, respectively.
As can be seen from TABLE III, both fixed representation
and fine-tuning lead to a significant degradation in open recognition performance regardless of the datasets, demonstrating
that adaptive representation learning indeed introduces great
benefits to incremental update.
However, the two have opposite effects on old and new
families. Due to the representation drift issue, fixed representation causes serious confusion between new families and others
(i.e., old and unknown families), resulting in many new family

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

1464

IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024

Fig. 7. Performance comparison for different values of λ1 and λ2 . Results
are obtained using the MAF metric at N = 7 with an incremental setting of
4 old families plus 3 new families.

instances being misclassified.4 Therefore, for new families, the
MAF values obtained by fixed representation are lower than
those achieved by fine-tuning. Since fine-tuning suffers from
the catastrophic forgetting issue causing numerous old family
instances to be misclassified, the recognition performance of
old families deteriorates more severely when using fine-tuning
than when using fixed representation.
These results also suggest that adaptive representation is
crucial for alleviating the representation drift issue to learn new
knowledge and that exemplar replay can effectively mitigate
the catastrophic forgetting issue to preserve old knowledge.
D. Sensitivity
This section conducts additional experiments on the
Drebin_NT dataset to further study other factors that may
affect the performance of DOMR.
1) Hyperparameters: Given that the hyperparameters
λ1 and λ2 control the learning of new families and the
knowledge consolidation of old families, we vary them in
{0.01, 0.1, 1, 10, 100} to investigate their impact on the incremental recognition performance of DOMR. As shown in
Fig. 7, the performance generally improves when varying
λ2 from 0.01 to 100, which is reasonable since an increase in
λ2 encourages the recognition model to retain more previously
learned knowledge about old families. Furthermore, it can be
seen that the optimal performance is achieved on the diagonal,
especially when neither of the parameters takes a value less
than 1.
2) Sample Size: To investigate whether DOMR is sensitive
to the sample size of families,5 we utilize different percentages
of instances per family in the training set to build recognition
models and then measure their open recognition performance
on the test set. Intuitively, a decrease in the sample size
of families would affect their fitting, so we simultaneously
observe the performance on known family classification.
4 Although both EVM and this ablation study show severe confusion
between new and unknown families because of fixed representation, a large
number of unknown family instances are misclassified as new families for
EVM and the opposite for this experiment due to differences in decisionmaking mechanism.
5 Previous work [33] has shown that class sample size has a significant
impact on family recognition performance.

Fig. 8. Performance comparison for different percentages of samples per
family. Results are obtained with an open setting of N = 4.

As shown in Fig. 8, the known family classification performance unsurprisingly degrades as the sample size decreases,
with the MAF value dropping to 45.64% when using 10% of
samples per family (in this case, several families have fewer
than 10 training samples, leading to severe overfitting); and
of course, the open recognition performance declines as well.
Moreover, the MAF for known family classification improves
to 71.85% when using 50% of samples per family (all families
have no less than 20 samples at this point), and it exceeds
90% when using 80% of samples per family (all families have
more than 40 samples at this point). These results indicate
that our method DOMR, despite achieving good recognition
performance with sufficient samples per family, is less robust
to small sample size, especially for the few-shot setting with
fewer than 10 samples.
3) Temporal Evolution: In the preceding subsections, our
evaluation protocols employ random sampling to partition the
datasets to verify the recognition performance of DOMR.
Here, we further investigate the temporal performance of
DOMR using the Drebin_NT dataset divided by sample release
time. To do so, we first download the JSON report of each
malware from VirusTotal [34], parse the report to obtain its
first submission time, and approximate that time as the sample’s release time, after which recognition models are trained
and tested by month. Specifically, we utilize samples released
before a given month of a year to build a recognition model for
that month and evaluate the model using samples released in
that month. Note that the models except for January are built
by incremental update rather than retraining from scratch. For
comparison, we directly apply the model trained in January
to all subsequent months’ evaluations without updating. The
results are shown in Fig. 9.
Due to the lack of training samples, the recognition performance in the first two months is relatively low, with the
MAF values not exceeding 30%. As time passes, the sample
size increases and the performance consequently improves.
Nevertheless, the MAF values drop slightly in some months,
which is mainly caused by representation drift; fortunately,
DOMR is able to mitigate this issue through continuous
updating, and thus the MAF values increase significantly in
the following months. Overall, the recognition performance
of DOMR improves over time and is consistently better than
that achieved by the model without updating.

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

LU AND WANG: DOMR: TOWARD DEEP OPEN-WORLD MALWARE RECOGNITION

Fig. 9. Temporal performance of DOMR. NU refers to the case of using the
model trained in January without updating it over time.
TABLE IV
OVERHEAD C OMPARISON B ETWEEN I NCREMENTAL U PDATE (IU)
AND R ETRAINING F ROM S CRATCH (RFS). R ESULTS A RE O BTAINED
W ITH AN I NCREMENTAL S ETTING OF 4 O LD
FAMILIES P LUS 3 N EW FAMILIES

4) Incremental Overhead: To understand the advantages of
incremental update over retraining from scratch, we compare
the two in terms of storage and time costs. Storage cost is the
number of old family samples that need to be stored, and time
cost is the time required to train a model. As can be seen from
TABLE IV, retraining from scratch is much more expensive
than incremental update, with storage and time costs 4.32 and
1.16 times higher, respectively. Given that incremental update
greatly reduces overhead even on our small-scale dataset, one
can speculate that it would be more useful for large-scale data.
V. R ELATED W ORK
1) Android Malware Detection: Android malware detection, which is dedicated to identifying whether a given Android
application is malicious or not, has been extensively studied
in the last two decades. A large number of static-based [19],
[35], [36], [37], dynamic-based [38], [39], [40], [41], and
hybrid-based approaches [42], [43], [44], [45] have been proposed. While these efforts play an important role in defending
against Android malware, they do not provide any additional
information that would aid in defense planning. Therefore,
there is a need to study more fine-grained Android malware
defense techniques, such as Android malware classification.
2) Android Malware Classification: Android malware classification has been a vivid research area over the years,
focusing mainly on two tasks: functionality recognition and
family recognition. The former concentrates on functional
behaviors and associates a malware sample with a single
functional label [46] or multiple functional labels [47]. The
latter is concerned with familial behaviors and categorizes
malware into a certain family. While both tasks are important,
the focus of this work is on family recognition.
Numerous machine learning-based techniques have been
proposed for Android malware family recognition, such as
[48], [49], [50], [51], [52]. However, these methods rely heav-

1465

ily on domain experts to design classification features, which is
time-consuming and labor-intensive, and hand-crafted features
are also failure-prone to deal with emerging sophisticated
variants.
In this context, deep learning-based techniques have recently
received considerable attention and achieved state-of-theart performance. Most existing methods represent Android
malware as images and then convert the malware family recognition problem into a deep learning-based image classification
task. For example, Tang et al. [11] converted the opcode
features extracted from a malware sample into a grayscale
image and designed a CNN-based image classification model
to implement family recognition. Wu et al. [9] transformed
the function call graphs of malware samples into greyscale
images and performed contrastive learning on the generated
images to train a CNN for classification. Iadarola et al. [7]
converted malware samples directly byte-by-byte to pixels
to generate grayscale images for classification. Yuan et al.
[53] modeled the byte stream of a malware sample as a
Markov chain and generated Markov images for classification
through first-order transition probabilities. There have also
been attempts to utilize graph representation learning techniques for malware family recognition. For instance, Gao et
al. [6] mapped malicious applications and Android APIs into
a heterogeneous graph that is fed into a graph convolutional
network (GCN) to build a node embedding model for family
recognition. Li et al. [54] extracted the function call graph of
a malware sample and used a GCN to embed all the nodes
of the graph to generate structural features for subsequent
classification. Pei et al. [55] represented malware samples
as graphs with node attributes that are word embeddings of
permissions, components, and APIs, and employed a GCN
and a recurrent neural network to learn higher-level graphical
semantics for classification. However, these approaches are
tailored for a static closed world and thus lack the capabilities
of detecting unknown malware families and continuously
learning the unknown, rendering them prone to failure in open
and dynamic deployment environments.
Given this, our work focuses on open-world Android malware recognition that, to our knowledge, is still in its infancy.
Hassen and Chan [22] took a first step toward this subfield
and introduced the ii-loss function to learn an effective representation to facilitate open recognition. Nevertheless, the
proposed method exhibits lower recognition performance than
DOMR due to the lack of explicit optimization for unknown
families during training. In addition, this method does not take
into account the incremental update task and therefore cannot
incrementally adapt its knowledge in a dynamic environment.
3) Deep Open Recognition: Performing open recognition
with deep neural networks has become essential [56]. Bendale
and Boult [23] proposed OpenMax as the first solution for deep
open recognition, which redistributes the softmax classification
probabilities according to the Weibull probabilistic models
of known categories. Ge et al. [25] introduced G-OpenMax
that augments OpenMax with explicit probability estimation
over unknown categories, which is done based on unknown
category instances synthesized through generative adversarial
networks. Recently, Jang and Kim [24] presented OVRN-CD

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

1466

IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024

that replaces the softmax classification layer with multiple
sigmoid networks and fuses the logits of these sigmoid activations to conduct open recognition, which is extended from
DOC [26].
Despite the pioneering, these methods train the recognition
models by optimizing only cross-entropy loss that does not
directly incentivize projecting instances of the same class
closer together and instances of different classes farther apart,
resulting in overgeneralized decision boundaries for known
categories. Moreover, they are developed for image/text classification and have not been studied for the malware domain.
We ported them to the Android malware recognition task and
compared their performance with DOMR. There are other
deep open recognition methods designed for the image/text
classification domain, which will not be described here; for
more details, please refer to [27].
4) Class-Incremental Deep Learning: Class-incremental
learning is a practical way to adapt deep models to new
categories without retraining from scratch and catastrophically forgetting old classes. In the last decade, numerous
class-incremental deep learning approaches have been proposed, including techniques based on exemplar replay,
regularization, and parameter isolation, see [57] for more
details. Due to the simplicity and effectiveness of exemplar
replay-based techniques, DOMR employs a state-of-the-art
replay-based method, iCaRL [15], to support the incremental
update task. Note that we are not working on new proposals
for class-incremental learning.
5) Out-of-Distribution Detection: The malware community has recently made some progress in out-of-distribution
detection, such as [17], [58], [59], [60], which is a problem
related to open recognition but with a different setting. Out-ofdistribution detection works on detecting samples that deviate
from the training distribution regardless of whether they are
from an unknown class, which means that drifting samples
may be from known categories. Open recognition strives to
detect samples from unknown categories and is more challenging in comparison.

discovery of new families is a very interesting endeavor,
not only because it would make DOMR a fully automated
solution for deep open-world malware recognition, but more
importantly, it would significantly reduce the cost of human
labeling. With the help of unsupervised learning methods such
as contrastive clustering [61], it is possible to automatically
discover new families from the category c0 .
3) Incremental Update: Given the enormous challenges of
threshold tuning for open recognition, we employ a onevs-rest strategy to train multiple binary classifiers to make
the recognition decision of DOMR threshold-free. Also, this
strategy enables DOMR to easily scale during incremental
update, because only one more binary classifier needs to be
incorporated whenever a new malware family is encountered.
Nevertheless, with continuous updating, the size of the binary
classifiers becomes quite large, naturally incurring high storage
costs. Hence, how to jointly address both open recognition and
incremental update tasks more efficiently and cost-effectively
is an open issue.
For the sake of simplicity, at this stage we directly integrate exemplar replay-based incremental learning methods into
DOMR to provide incremental capabilities. Despite the superior incremental recognition performance achieved by DOMR
over the comparison approaches, there is still much room
for improvement. Investigating better incremental learning
methods and options for integrating them into DOMR is an
important future work.
4) Few-Shot Setting: As shown in Section IV-D, DOMR
is sensitive to sample size, and its recognition performance
degrades when the sample size is reduced, especially under the
few-shot setting. While it is beyond the scope of this paper,
the few-shot setting is a crucial and practical scenario, since
new malware families typically emerge with fewer samples.
Generalizing deep open-world malware recognition to the
few-shot setting is therefore an orthogonal but highly rewarding endeavor. Recent advances in meta-learning specialized for
few-shot learning (e.g., meta-transfer learning [62]) provide
the potential to deal with this problem, which is left to our
future work to enhance the robustness of DOMR.

VI. D ISCUSSION
As a first attempt toward deep open-world malware recognition, our approach suffers from several limitations. We now
discuss these limitations and point out future research directions below.
1) Open Recognition: As shown in Section IV-C, DOMR’s
performance on known family classification drops a bit
compared to that obtained after ablating the meta-learning
framework. Even though meta-learning does enable recognition models to generalize well to unknown detection, an ideal
open recognition method should not compromise known family classification performance for detecting unknown family
instances. We plan to further improve the overall open recognition performance of DOMR in the future, with pre-training
and data-augmentation techniques as feasible solutions.
2) New Family Discovery: Currently, DOMR does not
support automatic discovery of new families from the detected
unknown category c0 ; instead, we assume that new families are
manually labeled by security analysts. However, the automatic

VII. C ONCLUSION
Considering the open and dynamic nature of real deployment environments, this paper introduces a new problem
setting for Android malware family recognition, i.e., deep
open-world malware recognition, which breaks the closedworld assumption followed by current deep learning-based
approaches and models the real-life environments more
closely. We propose DOMR to address the open recognition
and incremental update tasks of this problem in a unified
framework, where an episode-based representation learning
scheme is designed to generate the open recognition model
and simultaneously support the model update. Our evaluation
shows the great potential of DOMR for open-world Android
malware recognition, outperforming the state-of-the-art methods in both open and incremental cases, and ablation studies
also highlight the significance of each novelty in DOMR.
We hope this work will inspire more research in this important
and open direction.

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

LU AND WANG: DOMR: TOWARD DEEP OPEN-WORLD MALWARE RECOGNITION

R EFERENCES
[1] T. Sharma and D. Rattan, “Malicious application detection in Android—
A systematic literature review,” Comput. Sci. Rev., vol. 40, May 2021,
Art. no. 100373.
[2] Y. Bai, Z. Xing, D. Ma, X. Li, and Z. Feng, “Comparative analysis of
feature representations and machine learning methods in Android family
classification,” Comput. Netw., vol. 184, Jan. 2021, Art. no. 107639.
[3] J. Qiu, J. Zhang, W. Luo, L. Pan, S. Nepal, and Y. Xiang, “A survey
of Android malware detection with deep neural models,” ACM Comput.
Surv., vol. 53, no. 6, pp. 1–36, Nov. 2021.
[4] M. Macas, C. Wu, and W. Fuertes, “A survey on deep learning for
cybersecurity: Progress, challenges, and opportunities,” Comput. Netw.,
vol. 212, Jul. 2022, Art. no. 109032.
[5] Z. Wang, K. W. Fok, and V. L. L. Thing, “Machine learning for
encrypted malicious traffic detection: Approaches, datasets and comparative study,” Comput. Secur., vol. 113, Feb. 2022, Art. no. 102542.
[6] H. Gao, S. Cheng, and W. Zhang, “GDroid: Android malware detection
and classification with graph convolutional network,” Comput. Secur.,
vol. 106, Jul. 2021, Art. no. 102264.
[7] G. Iadarola, F. Martinelli, F. Mercaldo, and A. Santone, “Towards an
interpretable deep learning model for mobile malware detection and family identification,” Comput. Secur., vol. 105, Jun. 2021, Art. no. 102198.
[8] R. Feng, S. Chen, X. Xie, G. Meng, S.-W. Lin, and Y. Liu,
“A performance-sensitive malware detection system using deep learning
on mobile devices,” IEEE Trans. Inf. Forensics Security, vol. 16,
pp. 1563–1578, 2021.
[9] Y. Wu, S. Dou, D. Zou, W. Yang, W. Qiang, and H. Jin, “Contrastive
learning for robust Android malware familial classification,” IEEE
Trans. Dependable Secure Comput., early access, Nov. 3, 2022, doi:
10.1109/TDSC.2022.3219082.
[10] T. Lu and J. Wang, “F2DC: Android malware classification based on
raw traffic and neural networks,” Comput. Netw., vol. 217, Nov. 2022,
Art. no. 109320.
[11] J. Tang, R. Li, Y. Jiang, X. Gu, and Y. Li, “Android malware obfuscation
variants detection method based on multi-granularity opcode features,”
Future Gener. Comput. Syst., vol. 129, pp. 141–151, Apr. 2022.
[12] F. Pendlebury, F. Pierazzi, R. Jordaney, J. Kinder, and L. Cavallaro,
“TESSERACT: Eliminating experimental bias in malware classification
across space and time,” in Proc. 28th USENIX Secur. Symp., Santa Clara,
CA, USA, Aug. 2019, pp. 729–746.
[13] D. Arp et al., “Dos and don’ts of machine learning in computer
security,” in Proc. 31st USENIX Secur. Symp., Boston, MA, USA, 2022,
pp. 3971–3988.
[14] K. J. Joseph, S. Khan, F. S. Khan, and V. N. Balasubramanian, “Towards
open world object detection,” in Proc. IEEE/CVF Conf. Comput. Vis.
Pattern Recognit. (CVPR), Jun. 2021, pp. 5826–5836.
[15] S.-A. Rebuffi, A. Kolesnikov, G. Sperl, and C. H. Lampert, “ICaRL:
Incremental classifier and representation learning,” in Proc. IEEE Conf.
Comput. Vis. Pattern Recognit. (CVPR), Honolulu, HI, USA, Jul. 2017,
pp. 5533–5542.
[16] R. French, “Catastrophic forgetting in connectionist networks,” Trends
Cognit. Sci., vol. 3, no. 4, pp. 128–135, Apr. 1999.
[17] L. Yang et al., “CADE: Detecting and explaining concept drift samples for security applications,” in Proc. 30th USENIX Secur. Symp.,
Vancouver, BC, Canada, 2021, pp. 2327–2344.
[18] J. Gama, I. Žliobaité, A. Bifet, M. Pechenizkiy, and A. Bouchachia,
“A survey on concept drift adaptation,” ACM Comput. Surv., vol. 46,
no. 4, pp. 1–37, Apr. 2014.
[19] D. Arp, M. Spreitzenbarth, M. Hübner, H. Gascon, and K. Rieck,
“Drebin: Effective and explainable detection of Android malware in
your pocket,” in Proc. Netw. Distrib. Syst. Secur. Symp., San Diego,
CA, USA, 2014, pp. 23–26.
[20] S. Mahdavifar, A. F. A. Kadir, R. Fatemi, D. Alhadidi, and
A. A. Ghorbani, “Dynamic Android malware category classification
using semi-supervised deep learning,” in Proc. IEEE Int. Conf Dependable, Autonomic Secure Comput., Int. Conf Pervasive Intell. Comput.,
Int. Conf Cloud Big Data Comput., Int. Conf Cyber Sci. Technol.
Congr. (DASC/PiCom/CBDCom/CyberSciTech), Calgary, AB, Canada,
Aug. 2020, pp. 515–522.
[21] B. Wang et al., “Neural cleanse: Identifying and mitigating backdoor
attacks in neural networks,” in Proc. IEEE Symp. Secur. Privacy (SP),
San Francisco, CA, USA, May 2019, pp. 707–723.
[22] M. Hassen and P. K. Chan, “Learning a neural-network-based representation for open set recognition,” in Proc. Int. Conf. Data Mining,
Cincinnati, OH, USA, May 2020, pp. 154–162.

1467

[23] A. Bendale and T. E. Boult, “Towards open set deep networks,” in Proc.
IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Las Vegas, NV,
USA, Jun. 2016, pp. 1563–1572.
[24] J. Jang and C. O. Kim, “Collective decision of one-vs-rest networks
for open-set recognition,” IEEE Trans. Neural Netw. Learn. Syst., early
access, Jul. 14, 2022, doi: 10.1109/TNNLS.2022.3189996.
[25] Z. Ge, S. Demyanov, and R. Garnavi, “Generative OpenMax for multiclass open set classification,” in Proc. Brit. Mach. Vis. Conf., London,
U.K., 2017, pp. 1–12.
[26] L. Shu, H. Xu, and B. Liu, “DOC: Deep open classification of text
documents,” in Proc. Conf. Empirical Methods Natural Lang. Process.,
Copenhagen, Denmark, 2017, pp. 2911–2916.
[27] C. Geng, S.-J. Huang, and S. Chen, “Recent advances in open set
recognition: A survey,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 43,
no. 10, pp. 3614–3631, Oct. 2021.
[28] C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for
fast adaptation of deep networks,” in Proc. Int. Conf. Mach. Lean.
(ICML), Sydney, NSW, Australia, Jun. 2017, pp. 1126–1135.
[29] A. Bendale and T. Boult, “Towards open world recognition,” in Proc.
IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Boston, MA, USA,
Jun. 2015, pp. 1893–1902.
[30] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,” Proc. IEEE, vol. 86, no. 11,
pp. 2278–2324, Nov. 1998.
[31] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
in Proc. 3rd Int. Conf. Learn. Represent., San Diego, CA, USA, 2015,
pp. 1–15.
[32] E. M. Rudd, L. P. Jain, W. J. Scheirer, and T. E. Boult, “The extreme
value machine,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 40, no. 3,
pp. 762–768, Mar. 2018.
[33] T. Beppler, M. Botacin, F. J. O. Ceschin, L. E. S. Oliveira, and A. Grégio,
“L(a)ying in (test) bed: How biased datasets produce impractical results
for actual malware families’ classification,” in Proc. 22nd Int. Conf. Inf.
Secur. (ISC), New York, NY, USA. Cham, Switzerland: Springer, 2019,
pp. 381–401.
[34] (2013). Virustotal. Accessed: Sep. 1, 2023. [Online]. Available:
https://www.virustotal.com/gui/home/upload
[35] L. Shi et al., “VAHunt: Warding off new repackaged Android malware
in app-virtualization’s clothing,” in Proc. ACM SIGSAC Conf. Comput.
Commun. Secur., Nov. 2020, pp. 535–549.
[36] X. Zhang et al., “Enhancing State-of-the-art classifiers with API semantics to detect evolved Android malware,” in Proc. ACM SIGSAC Conf.
Comput. Commun. Secur., Oct. 2020, pp. 757–770.
[37] B. Wang, C. Yang, and J. Ma, “IAFDroid: Demystifying collusion
attacks in Android ecosystem via precise inter-app analysis,” IEEE
Trans. Inf. Forensics Security, vol. 18, pp. 2883–2898, 2023.
[38] S. Wang, Q. Yan, Z. Chen, B. Yang, C. Zhao, and M. Conti, “Detecting
Android malware leveraging text semantics of network flows,” IEEE
Trans. Inf. Forensics Security, vol. 13, no. 5, pp. 1096–1109, May 2018.
[39] M. K. Alzaylaee, S. Y. Yerima, and S. Sezer, “DL-droid: Deep learning
based Android malware detection using real devices,” Comput. Secur.,
vol. 89, Feb. 2020, Art. no. 101663.
[40] G. Suarez-Tangil, J. E. Tapiador, F. Lombardi, and R. D. Pietro, “Alterdroid: Differential fault analysis of obfuscated smartphone malware,”
IEEE Trans. Mobile Comput., vol. 15, no. 4, pp. 789–802, Apr. 2016.
[41] E. Amer, I. Zelinka, and S. El-Sappagh, “A multi-perspective malware
detection approach through behavioral fusion of API call sequence,”
Comput. Secur., vol. 110, Nov. 2021, Art. no. 102449.
[42] T. Chakraborty, F. Pierazzi, and V. S. Subrahmanian, “EC2: Ensemble
clustering and classification for predicting Android malware families,”
IEEE Trans. Dependable Secure Comput., vol. 17, no. 2, pp. 262–277,
Mar. 2020.
[43] A. Saracino, D. Sgandurra, G. Dini, and F. Martinelli, “MADAM:
Effective and efficient behavior-based Android malware detection and
prevention,” IEEE Trans. Dependable Secure Comput., vol. 15, no. 1,
pp. 83–97, Jan. 2018.
[44] Q. Han, V. S. Subrahmanian, and Y. Xiong, “Android malware detection
via (somewhat) robust irreversible feature transformations,” IEEE Trans.
Inf. Forensics Security, vol. 15, pp. 3511–3525, 2020.
[45] E. Amer and S. El-Sappagh, “Robust deep learning early alarm prediction model based on the behavioural smell for Android malware,”
Comput. Secur., vol. 116, May 2022, Art. no. 102670.
[46] C.-C. Hu, T.-H. Jeng, and Y.-M. Chen, “Dynamic Android malware
analysis with de-identification of personal identifiable information,” in
Proc. 3rd Int. Conf. Comput. Big Data, 2020, pp. 30–36.

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

1468

IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024

[47] Q. Qiao, R. Feng, S. Chen, F. Zhang, and X. Li, “Multi-label
classification for Android malware based on active learning,” IEEE
Trans. Dependable Secure Comput., early access, Oct. 17, 2022, doi:
10.1109/TDSC.2022.3213689.
[48] K. O. Elish, M. O. Elish, and H. M. J. Almohri, “Lightweight, effective
detection and characterization of mobile malware families,” IEEE Trans.
Comput., vol. 71, no. 11, pp. 2982–2995, Nov. 2022.
[49] M. Zhang, Y. Duan, H. Yin, and Z. Zhao, “Semantics-aware Android
malware classification using weighted contextual API dependency
graphs,” in Proc. ACM SIGSAC Conf. Comput. Commun. Secur., Scottsdale, AZ, USA, Nov. 2014, pp. 1105–1116.
[50] M. Fan et al., “Android malware familial classification and representative
sample selection via frequent subgraph analysis,” IEEE Trans. Inf.
Forensics Security, vol. 13, no. 8, pp. 1890–1905, Aug. 2018.
[51] T. Gao, W. Peng, D. Sisodia, T. K. Saha, F. Li, and M. Al Hasan,
“Android malware detection via graphlet sampling,” IEEE Trans. Mobile
Comput., vol. 18, no. 12, pp. 2754–2767, Dec. 2019.
[52] N. Chawla, H. Kumar, and S. Mukhopadhyay, “Machine learning in
wavelet domain for electromagnetic emission based malware analysis,”
IEEE Trans. Inf. Forensics Security, vol. 16, pp. 3426–3441, 2021.
[53] B. Yuan, J. Wang, D. Liu, W. Guo, P. Wu, and X. Bao, “Byte-level
malware classification based on Markov images and deep learning,”
Comput. Secur., vol. 92, May 2020, Art. no. 101740.
[54] Q. Li, Q. Hu, Y. Qi, S. Qi, X. Liu, and P. Gao, “Semi-supervised
two-phase familial analysis of Android malware with normalized graph
embedding,” Knowl.-Based Syst., vol. 218, Apr. 2021, Art. no. 106802.
[55] X. Pei, L. Yu, and S. Tian, “AMalNet: A deep learning framework based
on graph convolutional networks for malware detection,” Comput. Secur.,
vol. 93, Jun. 2020, Art. no. 101792.
[56] T. E. Boult, S. Cruz, A. R. Dhamija, M. Gunther, J. Henrydoss, and
W. J. Scheirer, “Learning and the unknown: Surveying steps toward open
world recognition,” in Proc. 33rd AAAI Conf. Artif. Intell., Honolulu, HI,
USA, Jan. 2019, pp. 9801–9807.
[57] M. De Lange et al., “A continual learning survey: Defying forgetting in
classification tasks,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 44,
no. 7, pp. 3366–3385, Jul. 2022.
[58] R. Jordaney et al., “Transcend: Detecting concept drift in malware
classification models,” in Proc. 26th USENIX Secur. Symp., Vancouver,
BC, Canada, Aug. 2017, pp. 625–642.
[59] F. Barbero, F. Pendlebury, F. Pierazzi, and L. Cavallaro, “Transcending
TRANSCEND: Revisiting malware classification in the presence of
concept drift,” in Proc. IEEE Symp. Secur. Privacy (SP), San Francisco,
CA, USA, May 2022, pp. 805–823.

[60] F. Ceschin, M. Botacin, H. M. Gomes, F. Pinagé, L. S. Oliveira, and
A. Grégio, “Fast & furious: On the modelling of malware detection
as an evolving data stream,” Exp. Syst. Appl., vol. 212, Feb. 2023,
Art. no. 118590.
[61] Y. Li, P. Hu, J. Z. Liu, D. Peng, J. T. Zhou, and X. Peng, “Contrastive
clustering,” in Proc. 35th AAAI Conf. Artif. Intell., 2021, pp. 8547–8555.
[62] Q. Sun, Y. Liu, T.-S. Chua, and B. Schiele, “Meta-transfer learning
for few-shot learning,” in Proc. IEEE/CVF Conf. Comput. Vis. Pattern
Recognit. (CVPR), Long Beach, CA, USA, Jun. 2019, pp. 403–412.

Tingting Lu received the B.S. degree in computer
science from Sichuan University, Chengdu, in 2017,
where she is currently pursuing the Ph.D. degree
with the College of Computer Science. Her recent
research interests include mobile security and network traffic analysis.

Junfeng Wang received the M.S. degree in computer application technology from the Chongqing
University of Posts and Telecommunications,
Chongqing, in 2001, and the Ph.D. degree in
computer science from the University of Electronic
Science and Technology of China, Chengdu,
in 2004. From 2004 to 2006, he was a PostDoctoral Researcher with the Institute of Software,
Chinese Academy of Sciences. He is currently a
Professor with the College of Computer Science,
Sichuan University. His recent research interests
include spatial information networks, network and information security, and
intelligent transportation systems.

Authorized licensed use limited to: Nanchang University. Downloaded on October 27,2024 at 06:38:29 UTC from IEEE Xplore. Restrictions apply.

